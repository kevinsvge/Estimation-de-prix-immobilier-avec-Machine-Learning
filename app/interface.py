import streamlit as st
from transformers import pipeline

# Configuration de la page
st.set_page_config(page_title="R√©sumeur IA (GPU)", page_icon="üß†")

st.title("üß† R√©sumeur automatique de texte (version GPU avec PyTorch)")
st.markdown("Collez un texte long (article, email, rapport‚Ä¶) et obtenez un r√©sum√© g√©n√©r√© par l'IA.")

# Chargement du mod√®le (PyTorch + GPU si dispo)
@st.cache_resource
def load_model():
    return pipeline(
        "summarization",
        model="facebook/bart-large-cnn",
        framework="pt",  # ‚ö†Ô∏è Utilise PyTorch (GPU compatible)
        device=0 if torch.cuda.is_available() else -1
    )

# Import torch pour la gestion GPU
import torch
st.sidebar.markdown(f"üñ•Ô∏è **GPU disponible** : `{torch.cuda.get_device_name(0)}`" if torch.cuda.is_available() else "‚ö†Ô∏è Aucun GPU d√©tect√©.")

summarizer = load_model()

# Entr√©e utilisateur
text_input = st.text_area("üìÑ Texte √† r√©sumer :", height=250)

# Param√®tres r√©glables
st.sidebar.title("‚öôÔ∏è Param√®tres de r√©sum√©")
max_length = st.sidebar.slider("Longueur max du r√©sum√©", 50, 300, 130)
min_length = st.sidebar.slider("Longueur min du r√©sum√©", 10, 100, 30)

# R√©sum√©
if st.button("‚ú® R√©sumer le texte"):
    if text_input.strip() != "":
        with st.spinner("üí° R√©sum√© en cours avec l'acc√©l√©ration GPU..."):
            summary = summarizer(
                text_input,
                max_length=max_length,
                min_length=min_length,
                do_sample=False
            )
        st.subheader("üìù R√©sum√© g√©n√©r√© :")
        st.success(summary[0]['summary_text'])
    else:
        st.warning("Veuillez saisir un texte pour g√©n√©rer un r√©sum√©.")

# Footer
st.markdown("---")
st.caption("R√©sum√© IA propuls√© par [ü§ó Transformers](https://huggingface.co/facebook/bart-large-cnn) + [PyTorch](https://pytorch.org) ‚Äì Optimis√© GPU")
